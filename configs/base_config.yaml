project_name: "distilbert-go-emotions"
output_dir: "./outputs/go-emotions"

dataset:
  name: "go_emotions"
  subset: "simplified"
  # path: "data/go_emotions_cleaned" # Uncomment to use a local cleaned dataset
  split_names:
    train: "train"
    validation: "validation"
    test: "test"
  text_column: "text"
  label_column: "labels"

model:
  name: "distilbert-base-uncased"
  max_length: 128

training:
  learning_rate: 2.0e-5
  per_device_train_batch_size: 16
  per_device_eval_batch_size: 16
  num_train_epochs: 3
  weight_decay: 0.01
  logging_steps: 100
  evaluation_strategy: "epoch"
  save_strategy: "epoch"
  save_total_limit: 2
  seed: 42

peft:
  enabled: false # DISABLED: using full fine-tuning for simplicity
  r: 16
  lora_alpha: 32
  lora_dropout: 0.1
  bias: "none"
  task_type: "SEQ_CLS"

optuna:
  enabled: true

  n_trials: 3
  direction: "maximize"
