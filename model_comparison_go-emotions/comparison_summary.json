{
  "dataset": "go-emotions",
  "num_models_compared": 8,
  "models": [
    "Ensemble",
    "Weighted Classes",
    "Clean Baseline",
    "Baseline (Fine-tune)",
    "K-Fold CV",
    "Contrastive (SupCon)",
    "MLM Pretraining",
    "Partial Freezing"
  ],
  "metrics_compared": [
    "F1 Weighted",
    "F1 Micro",
    "Accuracy",
    "Precision",
    "Recall"
  ],
  "best_per_metric": {
    "F1 Weighted": {
      "model": "Ensemble",
      "score": 0.6048872296698561
    },
    "F1 Micro": {
      "model": "Ensemble",
      "score": 0.6136926889714994
    },
    "Accuracy": {
      "model": "Clean Baseline",
      "score": 0.5058043117744611
    },
    "Precision": {
      "model": "Partial Freezing",
      "score": 0.7112893230720376
    },
    "Recall": {
      "model": "Ensemble",
      "score": 0.6260072681308263
    }
  },
  "overall_best": "Ensemble",
  "comparison_table": [
    {
      "Model": "Ensemble",
      "F1 Weighted": 0.6048872296698561,
      "F1 Micro": 0.6136926889714994,
      "Accuracy": 0.4623180394324673,
      "Precision": 0.60185325839283,
      "Recall": 0.6260072681308263,
      "Avg Rank": 3.0
    },
    {
      "Model": "Weighted Classes",
      "F1 Weighted": 0.5845669974984139,
      "F1 Micro": 0.5857637552904963,
      "Accuracy": 0.4304403906393956,
      "Precision": 0.5748873441148014,
      "Recall": 0.6013588244588403,
      "Avg Rank": 5.0
    },
    {
      "Model": "Clean Baseline",
      "F1 Weighted": 0.5816490305508992,
      "F1 Micro": 0.6039915074309978,
      "Accuracy": 0.5058043117744611,
      "Precision": 0.631463651471153,
      "Recall": 0.561858113446042,
      "Avg Rank": 3.0
    },
    {
      "Model": "Baseline (Fine-tune)",
      "F1 Weighted": 0.5737558521029993,
      "F1 Micro": 0.5877308129867856,
      "Accuracy": 0.47392666298138936,
      "Precision": 0.6413996886940794,
      "Recall": 0.5305735503239059,
      "Avg Rank": 3.8
    },
    {
      "Model": "K-Fold CV",
      "F1 Weighted": 0.5732645773347016,
      "F1 Micro": 0.5887294364718236,
      "Accuracy": 0.47318960751796574,
      "Precision": 0.6388570731094195,
      "Recall": 0.531521567388213,
      "Avg Rank": 4.0
    },
    {
      "Model": "Contrastive (SupCon)",
      "F1 Weighted": 0.5562517428064865,
      "F1 Micro": 0.5779267850670533,
      "Accuracy": 0.46434494195688225,
      "Precision": 0.6544469919200281,
      "Recall": 0.5038710696792542,
      "Avg Rank": 5.0
    },
    {
      "Model": "MLM Pretraining",
      "F1 Weighted": 0.5399598744659804,
      "F1 Micro": 0.5745992601726264,
      "Accuracy": 0.45439469320066334,
      "Precision": 0.7017485376098529,
      "Recall": 0.47859061463106334,
      "Avg Rank": 5.8
    },
    {
      "Model": "Partial Freezing",
      "F1 Weighted": 0.5325077164318766,
      "F1 Micro": 0.5718963690648174,
      "Accuracy": 0.4490510410908421,
      "Precision": 0.7112893230720376,
      "Recall": 0.4691104439879918,
      "Avg Rank": 6.4
    }
  ]
}